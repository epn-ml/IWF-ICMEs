{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adequate-greeting",
   "metadata": {
    "tags": []
   },
   "source": [
    "This notebook documents the code used for the automatic detection of ICMEs in the full dataset with separate training. It is running on Python 3.8.5 with dependencies listed in the requirements.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "seeing-lindsay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_2900364/250635837.py:9: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 22:45:12.181537: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2900364/250635837.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_gpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/newtfvenv/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m               instructions)\n\u001b[0;32m--> 346\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_deprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/newtfvenv/lib/python3.8/site-packages/tensorflow/python/framework/test_util.py\u001b[0m in \u001b[0;36mis_gpu_available\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1665\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mlocal_device\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1666\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlocal_device\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"GPU\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m         \u001b[0mgpu_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpu_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_capability_from_device_desc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/newtfvenv/lib/python3.8/site-packages/tensorflow/python/client/device_lib.py\u001b[0m in \u001b[0;36mlist_local_devices\u001b[0;34m(session_config)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mserialized_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m   return [\n\u001b[0;32m---> 45\u001b[0;31m       \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_pywrap_device_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m   ]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory"
     ]
    }
   ],
   "source": [
    "#only run if GPU available\n",
    "\n",
    "#Set devices_id\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-convenience",
   "metadata": {},
   "outputs": [],
   "source": [
    "# at first, we want to import the necessary packages\n",
    "\n",
    "# Don't print warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pds\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import Precision, Recall, MeanIoU\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import CustomObjectScope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b4ab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import event as evt\n",
    "\n",
    "# load ICME catalog data\n",
    "\n",
    "[ic,header,parameters] = pickle.load(open('data/HELCATS_ICMECAT_v20_pandas.p', \"rb\" ))\n",
    "\n",
    "\n",
    "# extract important values\n",
    "\n",
    "isc = ic.loc[:,'sc_insitu'] \n",
    "starttime = ic.loc[:,'icme_start_time']\n",
    "endtime = ic.loc[:,'mo_end_time']\n",
    "\n",
    "# Event indices from Wind, STEREO A and STEREO B\n",
    "\n",
    "iwinind = np.where(isc == 'Wind')[0]\n",
    "istaind = np.where(isc == 'STEREO-A')[0]\n",
    "istbind = np.where(isc == 'STEREO-B')[0]\n",
    "\n",
    "winbegin = starttime[iwinind]\n",
    "winend = endtime[iwinind]\n",
    "\n",
    "stabegin = starttime[istaind]\n",
    "staend = endtime[istaind]\n",
    "\n",
    "stbbegin = starttime[istbind]\n",
    "stbend = endtime[istbind]\n",
    "\n",
    "# get list of events\n",
    "\n",
    "evtListw = evt.read_cat(winbegin, winend, iwinind)\n",
    "evtLista = evt.read_cat(stabegin, staend, istaind)\n",
    "evtListb = evt.read_cat(stbbegin, stbend, istbind)\n",
    "\n",
    "sci = 0 #0,1,2\n",
    "\n",
    "if sci == 0:\n",
    "    # Load Wind data\n",
    "    [win, winheader] = pickle.load(open(\"data/wind_2007_2021_heeq_ndarray.p\", \"rb\"))\n",
    "\n",
    "if sci == 1:\n",
    "    # Load STEREO-A data\n",
    "    [sta, atta] = pickle.load(open(\"data/stereoa_2007_2021_sceq_ndarray.p\", \"rb\"))\n",
    "\n",
    "if sci == 2:\n",
    "    # Load STEREO-B data\n",
    "    [stb, attb, bheader] = pickle.load(open(\"data/stereob_2007_2014_sceq_ndarray.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed50218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import features\n",
    "\n",
    "if sci == 0:\n",
    "    \n",
    "    # pre process on the WIND data set\n",
    "\n",
    "    datawin = pds.DataFrame(win)\n",
    "    datawin['time'] = matplotlib.dates.num2date(datawin['time'], tz=None) \n",
    "    datawin['time'] = pds.to_datetime(datawin['time'], format=\"%Y/%m/%d %H:%M\")\n",
    "    datawin.set_index('time',  inplace=True)\n",
    "    datawin.index.name = None\n",
    "    datawin.index = datawin.index.tz_localize(None)\n",
    "    datawin.drop(['x', 'y', 'z', 'r', 'lat', 'lon'], axis = 1,  inplace=True)\n",
    "\n",
    "    # compute additional features\n",
    "\n",
    "    features.computeBetawiki(datawin)\n",
    "    features.computePdyn(datawin)\n",
    "    features.computeTexrat(datawin)\n",
    "\n",
    "    # resample data\n",
    "    datawin = datawin.resample('10T').mean().dropna()\n",
    "\n",
    "if sci == 1:\n",
    "    # pre process on the STEREO A data set\n",
    "\n",
    "    dataa = pds.DataFrame(sta)\n",
    "    dataa['time'] = matplotlib.dates.num2date(dataa['time'], tz=None) \n",
    "    dataa['time'] = pds.to_datetime(dataa['time'], format=\"%Y/%m/%d %H:%M\")\n",
    "    dataa.set_index('time',  inplace=True)\n",
    "    dataa.index.name = None\n",
    "    dataa.index = dataa.index.tz_localize(None)\n",
    "    dataa.drop(['x', 'y', 'z', 'r', 'lat', 'lon'], axis = 1,  inplace=True)\n",
    "\n",
    "    # compute additional features\n",
    "\n",
    "    features.computeBetawiki(dataa)\n",
    "    features.computePdyn(dataa)\n",
    "    features.computeTexrat(dataa)\n",
    "\n",
    "    # resample data\n",
    "    dataa = dataa.resample('10T').mean().dropna()\n",
    "\n",
    "if sci == 2:\n",
    "    # pre process on the STEREO B data set\n",
    "\n",
    "    datab = pds.DataFrame(stb)\n",
    "    datab['time'] = matplotlib.dates.num2date(datab['time'], tz=None) \n",
    "    datab['time'] = pds.to_datetime(datab['time'], format=\"%Y/%m/%d %H:%M\")\n",
    "    datab.set_index('time',  inplace=True)\n",
    "    datab.index.name = None\n",
    "    datab.index = datab.index.tz_localize(None)\n",
    "    datab.drop(['x', 'y', 'z', 'r', 'lat', 'lon'], axis = 1,  inplace=True)\n",
    "\n",
    "    # compute additional features\n",
    "    \n",
    "    features.computeBetawiki(datab)\n",
    "    features.computePdyn(datab)\n",
    "    features.computeTexrat(datab)\n",
    "\n",
    "    # resample data\n",
    "    datab = datab.resample('10T').mean().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f262667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete empty events\n",
    "\n",
    "if sci == 0:\n",
    "    evtListw = evt.clearempties(evtListw,datawin)\n",
    "if sci == 1:\n",
    "    evtLista = evt.clearempties(evtLista,dataa)\n",
    "if sci == 2:\n",
    "    evtListb = evt.clearempties(evtListb,datab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-gross",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sci == 0:\n",
    "    # perform scaling on WIND\n",
    "\n",
    "    scale = StandardScaler()\n",
    "    scale.fit(datawin)\n",
    "\n",
    "    wind_scaled = pds.DataFrame(index = datawin.index, columns = datawin.columns, data = scale.transform(datawin))\n",
    "\n",
    "if sci == 1:\n",
    "    # perform scaling on STEREO A\n",
    "\n",
    "    scale = StandardScaler()\n",
    "    scale.fit(dataa)\n",
    "\n",
    "    sta_scaled = pds.DataFrame(index = dataa.index, columns = dataa.columns, data = scale.transform(dataa))\n",
    "\n",
    "if sci == 2:\n",
    "    # perform scaling on STEREO B\n",
    "\n",
    "    scale = StandardScaler()\n",
    "    scale.fit(datab)\n",
    "\n",
    "    stb_scaled = pds.DataFrame(index = datab.index, columns = datab.columns, data = scale.transform(datab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83a2267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess\n",
    "\n",
    "if sci == 0:\n",
    "    truelabelw = pds.DataFrame(preprocess.get_truelabel(wind_scaled, evtListw))\n",
    "if sci == 1:\n",
    "    truelabela = pds.DataFrame(preprocess.get_truelabel(sta_scaled, evtLista))\n",
    "if sci == 2:\n",
    "    truelabelb = pds.DataFrame(preprocess.get_truelabel(stb_scaled, evtListb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089bc758",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "split = 4\n",
    "\n",
    "if sci == 0:\n",
    "    testw, valw, trainw = preprocess.getbalancedsplit(split, 'wind')\n",
    "    X_test, Y_test, X_val, Y_val, X_train, Y_train = preprocess.getdatas(trainw,testw,valw,wind_scaled,truelabelw)\n",
    "\n",
    "if sci == 1:\n",
    "    testa, vala, traina = preprocess.getbalancedsplit(split, 'stereoa') \n",
    "    X_test, Y_test, X_val, Y_val, X_train, Y_train = preprocess.getdatas(traina,testa,vala,sta_scaled,truelabela)\n",
    "\n",
    "if sci == 2:\n",
    "    testb, valb, trainb = preprocess.getbalancedsplit(split, 'stereob') \n",
    "    X_test, Y_test, X_val, Y_val, X_train, Y_train = preprocess.getdatas(trainb,testb,valb,stb_scaled,truelabelb)\n",
    "\n",
    "\n",
    "print(preprocess.printpercentage(Y_test))\n",
    "print(preprocess.printpercentage(Y_train))\n",
    "print(preprocess.printpercentage(Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c89224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import dice_coef, dice_loss, true_skill_score\n",
    "from unetgen import UnetGen\n",
    "from cycliclr import *\n",
    "\n",
    "if sci ==0:\n",
    "    model_path = \"modelw\" + str(split)\n",
    "    \n",
    "if sci ==1:\n",
    "    model_path = \"modela\" + str(split)\n",
    "    \n",
    "if sci ==2:\n",
    "    model_path = \"modelb\" + str(split)\n",
    "\n",
    "## Parameters\n",
    "\n",
    "C = 10 # number of channels\n",
    "t = 1024 # window size\n",
    "image_size = (t,1,C)\n",
    "batch_size = 32\n",
    "epochs =500\n",
    "expclr = CyclicLR(base_lr=0.00001, max_lr=0.01, step_size=1000)\n",
    "\n",
    "## Generator\n",
    "train_gen = UnetGen(X_train, Y_train, length=int(t), stride = 120,shuffle=True, batch_size=batch_size)\n",
    "valid_gen = UnetGen(X_val, Y_val, length=int(t), stride = 120,shuffle=True,batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd41d7e5",
   "metadata": {},
   "source": [
    "Next, we build the model and initiate some callbacks. We also select suitable metrics and start the training process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a8db8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ResUnetPlusPlus\n",
    "\n",
    "#### ResUnet++\n",
    "\n",
    "arch = ResUnetPlusPlus(input_shape=image_size)\n",
    "model = arch.build_model()\n",
    "\n",
    "optimizer = Adam()\n",
    "\n",
    "metrics = [Recall(), Precision(), dice_coef,true_skill_score, MeanIoU(num_classes=2)]\n",
    "model.compile(loss=dice_loss, optimizer=optimizer, metrics=metrics) \n",
    "\n",
    "checkpoint = ModelCheckpoint(model_path, verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "callbacks = [checkpoint, early_stopping,expclr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ea2c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to train\n",
    "#model.fit(train_gen, validation_data=valid_gen, epochs=epochs, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fadea7f",
   "metadata": {},
   "source": [
    "After the training process is finished, we continue by testing our model on unseen data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9f246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import postprocess\n",
    "from glob import glob\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "\n",
    "## Model\n",
    "with CustomObjectScope({'dice_loss': dice_loss, 'dice_coef': dice_coef, 'true_skill_score': true_skill_score}):\n",
    "    model = load_model(model_path)\n",
    "\n",
    "# TEST WIND\n",
    "\n",
    "test_gen = UnetGen(X_test, Y_test, length=int(t), stride = int(t),batch_size=batch_size)\n",
    "\n",
    "model.evaluate(test_gen, verbose=1)\n",
    "\n",
    "result = postprocess.generate_result(X_test, Y_test, model,C,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552449c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate WIND\n",
    "\n",
    "result.index = pds.to_datetime(result.index)\n",
    "resultbin = postprocess.make_binary(result['pred'], 0.5)\n",
    "events = postprocess.makeEventList(resultbin, 1, 10)\n",
    "ICMEs = postprocess.removeCreepy(events, 3)\n",
    "if sci == 0:\n",
    "    test_clouds = [x for x in evtListw if (x.begin.year in testw)]\n",
    "    \n",
    "if sci == 1:\n",
    "    test_clouds = [x for x in evtLista if (x.begin.year in testa)]\n",
    "\n",
    "if sci == 2:\n",
    "    test_clouds = [x for x in evtListb if (x.begin.year in testb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5171298-c547-44e3-8987-29bc6a03e06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP, FN, FP, detected = postprocess.evaluate(ICMEs, test_clouds, thres=0.1)\n",
    "print('Precision is:',len(TP)/(len(TP)+len(FP)))\n",
    "print('Recall is:',len(TP)/(len(TP)+len(FN)))\n",
    "print('True Positives', len(TP))\n",
    "print('False Negatives', len(FN))\n",
    "print('False Positives', len(FP))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "from cm import make_confusion_matrix\n",
    "\n",
    "if sci ==0:\n",
    "    startlagw = []\n",
    "    endlagw = []\n",
    "\n",
    "    for i in range(0, len(detectedw)):\n",
    "        predstartw = TPw[i].begin\n",
    "        predendw = TPw[i].end\n",
    "        startlagw.append((predstartw-detectedw[i].begin).total_seconds()/60)\n",
    "        endlagw.append((predendw-detectedw[i].end).total_seconds()/60)\n",
    "        \n",
    "    with open('startlagw'+str(split)+'.p', 'wb') as fp:\n",
    "        pickle.dump(startlagw, fp)\n",
    "    \n",
    "    with open('endlagw'+str(split)+'.p', 'wb') as fp:\n",
    "        pickle.dump(endlagw, fp)\n",
    "        \n",
    "    cmw = confusion_matrix(resultw['true'], resultbinw)\n",
    "\n",
    "    np.savetxt('cmw'+str(split)+'.txt',cmw)\n",
    "    cmeventw = np.array([[0,len(FPw)],[len(FNw),len(TPw)]])\n",
    "    np.savetxt('cmeventw'+str(split)+'.txt',cmeventw)\n",
    "    \n",
    "\n",
    "if sci==1:\n",
    "    startlaga = []\n",
    "    endlaga = []\n",
    "\n",
    "    for i in range(0, len(detecteda)):\n",
    "        predstarta = TPa[i].begin\n",
    "        predenda = TPa[i].end\n",
    "        startlaga.append((predstarta-detecteda[i].begin).total_seconds()/60)\n",
    "        endlaga.append((predenda-detecteda[i].end).total_seconds()/60)\n",
    "        \n",
    "    with open('startlaga'+str(split)+'.p', 'wb') as fp:\n",
    "        pickle.dump(startlaga, fp)\n",
    "    \n",
    "    with open('endlaga'+str(split)+'.p', 'wb') as fp:\n",
    "        pickle.dump(endlaga, fp)\n",
    "    cma = confusion_matrix(resulta['true'], resultbina)\n",
    "    \n",
    "    np.savetxt('cma'+str(split)+'.txt',cma)\n",
    "    cmeventa = np.array([[0,len(FPa)],[len(FNa),len(TPa)]])\n",
    "    np.savetxt('cmeventa'+str(split)+'.txt',cmeventa)\n",
    "\n",
    "\n",
    "    \n",
    "if sci==2:\n",
    "    startlagb = []\n",
    "    endlagb = []\n",
    "\n",
    "    for i in range(0, len(detectedb)):\n",
    "        predstartb = TPb[i].begin\n",
    "        predendb = TPb[i].end\n",
    "        startlagb.append((predstartb-detectedb[i].begin).total_seconds()/60)\n",
    "        endlagb.append((predendb-detectedb[i].end).total_seconds()/60)\n",
    "        \n",
    "    with open('startlagb'+str(split)+'.p', 'wb') as fp:\n",
    "        pickle.dump(startlagb, fp)\n",
    "    \n",
    "    with open('endlagb'+str(split)+'.p', 'wb') as fp:\n",
    "        pickle.dump(endlagb, fp)\n",
    "        \n",
    "    cmb = confusion_matrix(resultb['true'], resultbinb)\n",
    "\n",
    "    np.savetxt('cmb'+str(split)+'.txt',cmb)\n",
    "    cmeventb = np.array([[0,len(FPb)],[len(FNb),len(TPb)]])\n",
    "    np.savetxt('cmeventb'+str(split)+'.txt',cmeventb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-transaction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newtfvenv",
   "language": "python",
   "name": "newtfvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
